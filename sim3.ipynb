{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "from pylab import *\n",
      "from numpy import *\n",
      "from numpy.random import randn\n",
      "from random import choice, random, gauss\n",
      "from collections import defaultdict"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class svm_model:\n",
      "    def __init__(self, lmbda, dim):\n",
      "        self.dim = dim\n",
      "        self.w = zeros(dim)\n",
      "        self.lmbda = lmbda\n",
      "\n",
      "    def copy(self):\n",
      "        m = hinge_model(self.lmbda, self.dim)\n",
      "        m.w = self.w.copy()\n",
      "        return m\n",
      "\n",
      "    def set(self, other):\n",
      "        self.w = other.w.copy()\n",
      "        self.lmbda = other.lmbda\n",
      "        self.dim = other.dim\n",
      "\n",
      "    def randomize_model(self,  scale=1.0, density=1.0):\n",
      "        for i in range(0, self.dim):\n",
      "            self.w[i] = gaus(0, scale) if random() < density else 0.\n",
      "\n",
      "    def gradient(self, x, y):\n",
      "        prod = y * (self.w.dot(x))\n",
      "        return self.lmbda * self.w - ((y * x) if prod < 1 else 0)\n",
      "\n",
      "    def apply_gradient(self, grad, eta):\n",
      "        self.w -= eta * grad\n",
      "        return self.w\n",
      "\n",
      "    # def learn(self, x, y, t):\n",
      "    #     eta = 1.0/(self.lmbda*(t+1))\n",
      "    #     prod = y * (self.w.dot(x))\n",
      "    #     grad = self.lmbda * w - ((y * x) if prod < 1 else 0)\n",
      "    #     self.w -= eta*grad\n",
      "    #     return self.w\n",
      "\n",
      "    def predict(self, x):\n",
      "        sign(self.w.dot(x))\n",
      "\n",
      "    def point_loss(self, x, y):\n",
      "        return max(0., 1. - y*(self.w.dot(x)))\n",
      "\n",
      "    def data_loss(self, data):\n",
      "        loss = 0.\n",
      "        for (x, y) in data:\n",
      "            loss += max(0., 1. - y*(self.w.dot(x)))\n",
      "        return loss\n",
      "\n",
      "    def model_loss(self):\n",
      "        return pow(linalg.norm(self.w), 2)*lmbda/2\n",
      "\n",
      "    def loss(self, data):\n",
      "        dataLoss(self.w, data) + modelLoss(self.w, lmbda)\n",
      "\n",
      "    def pred_accuracy(self, data):\n",
      "        correct = 0\n",
      "        for (x,y) in data:\n",
      "            correct += 1 if y * self.w.dot(x) >= 0 else 0\n",
      "        double(correct) / len(data)\n",
      "\n",
      "    def average_models(self, models):\n",
      "        self.lbmda = models[0].lmbda\n",
      "        self.dim = len(models[0])\n",
      "        new_w = zeros(dim)\n",
      "        for m in models:\n",
      "            new_w += m.w\n",
      "        self.w = new_w / double(len(models))\n",
      "        return self.w\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 55
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def serial_SGD(model, data, iterations, initial_t=0):\n",
      "    history = []\n",
      "    for t in range(initial_t, initial_t+iterations):\n",
      "        (x, y) = choice(data)\n",
      "        grad = model.gradient(x, y)\n",
      "        eta = 1.0/(model.lmbda*(t+1))\n",
      "        model.apply_gradient(grad, eta)\n",
      "        history.append(model.copy())\n",
      "    return history"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def batch_AVG_SGD(model, data_group, iterations, initial_t=0):\n",
      "    # Advance all the models serially\n",
      "    histories = []\n",
      "    local_models = []\n",
      "    for data in data_group:\n",
      "        local_model = model.copy()\n",
      "        history = serial_SGD(local_model, data, iterations, initial_t)\n",
      "        histories.append(history)\n",
      "        local_models.append(local_model)\n",
      "    model.average_models(local_models)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def bsp_Hogwild(model_group, data_group, iterations, initial_t=0):\n",
      "    # Advance all the models serially\n",
      "    deltas = {}\n",
      "    for (model, data) in zip(model_group, data_group):\n",
      "        for t in range(initial_t, initial_t+iterations):\n",
      "            (x, y) = choice(data)\n",
      "            grad = model.gradient(x, y)\n",
      "            eta = 1.0/(model.lmbda*(t+1))\n",
      "            model.apply_gradient(grad, eta)\n",
      "            deltas\n",
      "            (x, y) = choice(data)\n",
      "        grad = model.gradient(x, y)\n",
      "        eta = 1.0/(model.lmbda*(t+1))\n",
      "        model.apply_gradient(grad, eta)\n",
      "\n",
      "        serial_SGD(model, data, iterations, initial_t)\n",
      "    # Compute the averaged model\n",
      "    model_group[0].average_models(model_group)\n",
      "    # set all the models to be the model average\n",
      "    for model in model_group:\n",
      "        model.set(model_group[0])\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def mini_batch_GD(model, data_group, iterations, initial_t=0):\n",
      "    grad_sum = None\n",
      "    total = 0\n",
      "    # For each group of data, compute the gradient average\n",
      "    for data in data_group:\n",
      "        for t in range(initial_t, initial_t + iterations):\n",
      "            (x, y) = choice(data)\n",
      "            if grad_sum is None:\n",
      "                grad_sum = model.gradient(x, y)\n",
      "            else:\n",
      "                grad_sum += model.gradient(x, y)\n",
      "            total += 1\n",
      "    eta = 1.0/(model.lmbda*(initial_t+1))\n",
      "    model.apply_gradient(grad_sum / double(total), eta)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Data Generators"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "class Datagen:\n",
      "    UNIFORM = 0\n",
      "    SKEWED = 1\n",
      "    SPLIT = 2\n",
      "    POINT_CLOUD = 3\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def gen_synth_data(num_samples, dim, nprocs, proc, params):\n",
      "    noise = params['noise']\n",
      "    use_bias = params['bias']\n",
      "    if params['type'] == Datagen.POINT_CLOUD:\n",
      "        pluscloud = array(params['offset1'] * ones(dim))\n",
      "        negcloud = array(params['offset2'] * ones(dim))\n",
      "\n",
      "        cloud_var = params['cloud_var']\n",
      "        isplus = (proc % 2) == 0\n",
      "        cloud_center = pluscloud if isplus else negcloud\n",
      "        y = 1 if isplus else -1\n",
      "        data = []\n",
      "    \n",
      "        for i in range(0, num_samples):\n",
      "            # Generate X\n",
      "            x = cloud_center + cloud_var * randn(dim)\n",
      "            # Add bias term if necessary\n",
      "            if use_bias:\n",
      "                x = append(x, 1.)\n",
      "            # Generate\n",
      "            obsY = y if random() < noise else -y\n",
      "            data.append((x, obsY))\n",
      "        return data\n",
      "    if params['type'] == Datagen.SPLIT:\n",
      "        if use_bias:\n",
      "            dim += 1\n",
      "        true_w = randn(dim)\n",
      "        cloud_var = params['cloud_var']\n",
      "        data = []\n",
      "        for i in range(0, num_samples):\n",
      "            # Generate X\n",
      "            x = randn(dim)\n",
      "            # set the bias term\n",
      "            if hasBias:\n",
      "                x[-1] = 1.\n",
      "            y = 1 if w_train.dot(x) > 0 else -1\n",
      "            if random() < noise:\n",
      "                y = -y\n",
      "            data.append((x,y))\n",
      "        return data\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def plot_data(data, model = None):\n",
      "    plot([x[0] for (x,y) in data if y == -1], [x[1] for (x,y) in data if y == -1], 'o', color=\"red\")\n",
      "    plot([x[0] for (x,y) in data if y == 1], [x[1] for (x,y) in data if y == 1], '+', color=\"blue\")\n",
      "    if model is not None:\n",
      "        plot([m[0] for m in MODEL_HIST[model]], [m[1] for m in MODEL_HIST[model]], 's-', color=\"black\")\n",
      "\n",
      "    show()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Experiments"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Experimental setup"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "DATA_PARAMS = {\n",
      "    'type': Datagen.POINT_CLOUD,\n",
      "    'noise': 0.0,\n",
      "    'offset1': 5.,\n",
      "    'offset2': 10.,\n",
      "    'cloud_var': 1,\n",
      "    'bias': True\n",
      "    }\n",
      "NUM_SAMPLES  = 1000\n",
      "DIM = 2\n",
      "NUM_PROCS = 4\n",
      "LMBDA = 0.1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "proc_data = {}\n",
      "for proc in range(0, NPROCS):\n",
      "    proc_data[proc] = gen_synth_data(NUM_SAMPLES, DIM, NUM_PROCS, proc, DATA_PARAMS)\n",
      "all_data = []\n",
      "for data in proc_data.values():\n",
      "    all_data += data\n",
      "    "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "plot_data(all_data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 49
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = svm_model(LMBDA, DIM+1)\n",
      "hist = serial_SGD(model, all_data, NUM_SAMPLES * 2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "loss = [m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}